"""
Service para intera√ß√£o com Llama/Ollama
"""
import requests
import json
import time
from typing import Dict, List, Optional, Any
from datetime import datetime

from .base_service import BaseService
from ..config import Config

class LlamaService(BaseService):
    """Service para intera√ß√£o com Llama via Ollama"""
    
    def _initialize(self):
        """Inicializar service"""
        self.base_url = Config.OLLAMA_BASE_URL
        self.model = Config.OLLAMA_MODEL
        self._test_connection()
        
        # Estat√≠sticas de uso
        self.usage_stats = {
            "total_requests": 0,
            "total_input_tokens": 0,
            "total_output_tokens": 0,
            "total_time": 0.0,
            "start_time": time.time()
        }
        
        # System prompt para an√°lise comercial
        self.system_prompt = """Voc√™ √© um especialista em an√°lise comercial e atendimento ao cliente. Sua fun√ß√£o √© analisar conversas do WhatsApp Business para extrair insights valiosos sobre:

1. QUALIDADE DO ATENDIMENTO: Avaliar se o funcion√°rio foi eficaz, cort√™s e profissional
2. SATISFA√á√ÉO DO CLIENTE: Identificar sinais de satisfa√ß√£o, insatisfa√ß√£o ou neutralidade
3. OPORTUNIDADES DE VENDA: Detectar chances de upsell, cross-sell ou convers√£o
4. PADR√ïES DE COMPORTAMENTO: Identificar necessidades, obje√ß√µes e prefer√™ncias dos clientes
5. MELHORIAS: Sugerir a√ß√µes para aprimorar vendas e relacionamento

DIRETRIZES:
- Seja objetivo e focado em insights acion√°veis
- Considere o contexto comercial e profissional
- Identifique padr√µes e tend√™ncias
- Forne√ßa feedback construtivo
- Use linguagem clara e direta
- Foque em dados que agregam valor ao neg√≥cio"""
    
    def _test_connection(self):
        """Testar conex√£o com Ollama"""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            response.raise_for_status()
            
            models = response.json().get('models', [])
            model_names = [model['name'] for model in models]
            
            if self.model in model_names:
                self.logger.info(f"‚úÖ Ollama conectado - Modelo {self.model} dispon√≠vel")
            else:
                self.logger.warning(f"‚ö†Ô∏è Modelo {self.model} n√£o encontrado")
                
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Ollama n√£o dispon√≠vel: {e}")
    
    def analyze_conversation(self, conversation_data: Dict) -> Dict:
        """Analisar conversa completa (DEPRECATED - usar analyze_diary)"""
        self._log_operation("an√°lise de conversa", {
            "conversation_id": conversation_data.get('conversation_id')
        })
        
        try:
            if not conversation_data or not conversation_data.get('contacts'):
                return {'error': 'Dados de conversa inv√°lidos'}
            
            # Preparar texto da conversa
            conversation_text = self._prepare_conversation_text(conversation_data)
            
            if not conversation_text.strip():
                return {'error': 'Conversa sem conte√∫do para an√°lise'}
            
            # An√°lise completa com prompts
            analysis = {
                'summary': self._generate_summary_with_prompt(conversation_text),
                'topics': self._extract_topics_with_prompt(conversation_text),
                'sentiment': self._analyze_sentiment_with_prompt(conversation_text),
                'insights': self._generate_insights_with_prompt(conversation_text),
                'conversation_stats': self._calculate_stats(conversation_data),
                'analyzed_at': datetime.now().isoformat()
            }
            
            self._log_success("an√°lise de conversa", {
                "conversation_id": conversation_data.get('conversation_id'),
                "topics_count": len(analysis['topics']['result']) if isinstance(analysis['topics'], dict) else len(analysis['topics']),
                "insights_count": len(analysis['insights']['result']) if isinstance(analysis['insights'], dict) else len(analysis['insights'])
            })
            
            return analysis
            
        except Exception as e:
            self._log_error("an√°lise de conversa", e)
            return {'error': str(e)}
    
    def analyze_diary(self, diary_data: Dict) -> Dict:
        """Analisar di√°rio completo - contatos individuais + resumo global (NOVO FLUXO)"""
        self._log_operation("an√°lise de di√°rio", {
            "diary_id": str(diary_data.get('_id')),
            "user_name": diary_data.get('user_name'),
            "contacts_count": len(diary_data.get('contacts', []))
        })
        
        try:
            if not diary_data or not diary_data.get('contacts'):
                return {'error': 'Dados de di√°rio inv√°lidos'}
            
            # 1. Analisar cada contato individualmente
            contact_analyses = []
            for contact_idx, contact in enumerate(diary_data.get('contacts', [])):
                contact_analysis = self._analyze_contact(contact, diary_data, contact_idx)
                if contact_analysis:
                    contact_analyses.append(contact_analysis)
            
            if not contact_analyses:
                return {'error': 'Nenhuma an√°lise de contato v√°lida gerada'}
            
            # 2. Gerar resumo global do di√°rio
            diary_summary = self._generate_diary_summary(contact_analyses, diary_data)
            
            # 3. Compilar resultado final
            result = {
                'contact_analyses': contact_analyses,
                'diary_summary': diary_summary,
                'analysis_stats': self._calculate_analysis_stats(contact_analyses, diary_data),
                'analyzed_at': datetime.now().isoformat()
            }
            
            self._log_success("an√°lise de di√°rio", {
                "diary_id": str(diary_data.get('_id')),
                "contacts_analyzed": len(contact_analyses),
                "analysis_success_rate": len([c for c in contact_analyses if c.get('success', False)]) / len(contact_analyses) * 100
            })
            
            return result
            
        except Exception as e:
            self.logger.error(f"Erro ao analisar di√°rio: {e}")
            self.logger.error(f"Tipo do erro: {type(e).__name__}")
            import traceback
            self.logger.error(f"Traceback completo: {traceback.format_exc()}")
            return {
                'error': str(e),
                'error_type': type(e).__name__,
                'success': False
            }
    
    def _prepare_conversation_text(self, conversation_data: Dict) -> str:
        """Preparar texto da conversa para an√°lise com contexto hist√≥rico"""
        text_parts = []
        
        # Adicionar contexto hist√≥rico se dispon√≠vel
        historical_context = conversation_data.get('historical_context', [])
        if historical_context:
            text_parts.append("=== CONTEXTO HIST√ìRICO (√öltimos 7 dias) ===")
            text_parts.append("Mensagens recentes do mesmo usu√°rio para contexto:")
            
            for msg in historical_context[:10]:  # Limitar a 10 mensagens hist√≥ricas
                timestamp = msg.get('timestamp', '')
                contact_name = msg.get('contact_name', 'Desconhecido')
                message_type = msg.get('message_type', 'text')
                text = msg.get('text', '')
                
                if text:
                    prefix = f"[{timestamp}] {contact_name}: " if timestamp else f"{contact_name}: "
                    
                    # Adicionar prefixo baseado no tipo
                    if message_type == 'audio_transcribed':
                        prefix += "[√ÅUDIO HIST√ìRICO] "
                    elif message_type == 'image_analyzed':
                        prefix += "[IMAGEM HIST√ìRICA] "
                    elif message_type in ['audio', 'image']:
                        prefix += f"[{message_type.upper()} HIST√ìRICO] "
                    
                    text_parts.append(f"{prefix}{text}")
            
            text_parts.append("\n=== CONVERSA ATUAL ===")
        
        # Adicionar conversa atual
        for contact in conversation_data.get('contacts', []):
            contact_name = contact.get('contact_name', 'Desconhecido')
            text_parts.append(f"\n=== Conversa com {contact_name} ===")
            
            for message in contact.get('messages', []):
                message_text = message.get('text', '')
                message_type = message.get('message_type', 'text')
                
                if message_text:
                    timestamp = message.get('timestamp', '')
                    prefix = f"[{timestamp}] {contact_name}: " if timestamp else f"{contact_name}: "
                    
                    # Adicionar prefixo baseado no tipo
                    if message_type == 'audio_transcribed':
                        prefix += "[√ÅUDIO TRANSCRITO] "
                    elif message_type == 'image_analyzed':
                        prefix += "[IMAGEM ANALISADA] "
                    elif message_type in ['audio', 'image']:
                        prefix += f"[{message_type.upper()}] "
                    
                    text_parts.append(f"{prefix}{message_text}")
        
        return "\n".join(text_parts)
    
    def _generate_summary(self, conversation_text: str) -> str:
        """Gerar resumo da conversa"""
        prompt = f"""
Analise esta conversa do WhatsApp e gere um resumo conciso em portugu√™s brasileiro.

Conversa:
{conversation_text}

Instru√ß√µes:
- Resuma os principais pontos da conversa
- Identifique o assunto principal
- Destaque informa√ß√µes importantes
- Seja objetivo e claro

Resumo:
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            return response.strip()
        except Exception as e:
            self.logger.error(f"Erro ao gerar resumo: {e}")
            return "Erro ao gerar resumo"
    
    def _generate_summary_with_prompt(self, conversation_text: str) -> Dict:
        """Gerar resumo da conversa com prompt"""
        prompt = f"""
Analise esta conversa do WhatsApp e gere um resumo conciso em portugu√™s brasileiro.

IMPORTANTE: A conversa pode incluir:
- Contexto hist√≥rico dos √∫ltimos 7 dias (marcado como HIST√ìRICO)
- Mensagens de √°udio transcritas (marcadas como [√ÅUDIO TRANSCRITO])
- An√°lises de imagens (marcadas como [IMAGEM ANALISADA])
- Mensagens de texto normais

Conversa:
{conversation_text}

Instru√ß√µes:
- Considere o contexto hist√≥rico para entender melhor a conversa atual
- Use as transcri√ß√µes de √°udio e an√°lises de imagem como conte√∫do real
- Resuma os principais pontos da conversa atual
- Identifique o assunto principal
- Destaque informa√ß√µes importantes
- Seja objetivo e claro

Resumo:
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            return {
                "result": response.strip(),
                "prompt": prompt,
                "success": True
            }
        except Exception as e:
            self.logger.error(f"Erro ao gerar resumo: {e}")
            return {
                "result": "Erro ao gerar resumo",
                "prompt": prompt,
                "success": False,
                "error": str(e)
            }
    
    def _extract_topics(self, conversation_text: str) -> List[str]:
        """Extrair t√≥picos principais"""
        prompt = f"""
Analise esta conversa do WhatsApp e identifique os principais t√≥picos discutidos.

Conversa:
{conversation_text}

Instru√ß√µes:
- Identifique 3-5 t√≥picos principais
- Use palavras-chave ou frases curtas
- Responda em formato de lista JSON
- Exemplo: ["trabalho", "fam√≠lia", "finan√ßas", "sa√∫de"]

T√≥picos (formato JSON):
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            try:
                topics = json.loads(response.strip())
                return topics if isinstance(topics, list) else [response.strip()]
            except json.JSONDecodeError:
                topics = [line.strip() for line in response.strip().split('\n') if line.strip()]
                return topics[:5]
        except Exception as e:
            self.logger.error(f"Erro ao extrair t√≥picos: {e}")
            return ["Erro ao extrair t√≥picos"]
    
    def _extract_topics_with_prompt(self, conversation_text: str) -> Dict:
        """Extrair t√≥picos principais com prompt"""
        prompt = f"""
Analise esta conversa do WhatsApp e identifique os principais t√≥picos discutidos.

IMPORTANTE: A conversa pode incluir:
- Contexto hist√≥rico dos √∫ltimos 7 dias (marcado como HIST√ìRICO)
- Mensagens de √°udio transcritas (marcadas como [√ÅUDIO TRANSCRITO])
- An√°lises de imagens (marcadas como [IMAGEM ANALISADA])
- Mensagens de texto normais

Conversa:
{conversation_text}

INSTRU√á√ïES CR√çTICAS:
- Identifique exatamente 3-5 t√≥picos principais da conversa atual
- Use palavras-chave ou frases curtas (m√°ximo 3 palavras por t√≥pico)
- Responda APENAS com uma lista JSON v√°lida
- N√ÉO inclua texto explicativo, apenas o JSON
- N√ÉO use markdown, apenas JSON puro

FORMATO OBRIGAT√ìRIO:
["t√≥pico1", "t√≥pico2", "t√≥pico3"]

EXEMPLOS V√ÅLIDOS:
["educa√ß√£o", "matr√≠cula", "cursos"]
["trabalho", "fam√≠lia", "finan√ßas"]
["sa√∫de", "m√©dico", "tratamento"]

Responda APENAS com o JSON:
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            response_clean = response.strip()
            
            # Tentar parse JSON direto
            try:
                topics = json.loads(response_clean)
                if isinstance(topics, list):
                    result = topics
                else:
                    result = [str(topics)]
            except json.JSONDecodeError:
                # Tentar extrair JSON da resposta
                import re
                json_match = re.search(r'\[.*?\]', response_clean, re.DOTALL)
                if json_match:
                    try:
                        topics = json.loads(json_match.group())
                        result = topics if isinstance(topics, list) else [str(topics)]
                    except json.JSONDecodeError:
                        # Fallback: extrair t√≥picos das linhas
                        lines = [line.strip() for line in response_clean.split('\n') if line.strip()]
                        result = [line.replace('"', '').replace(',', '').strip() for line in lines if line and not line.startswith(('Aqui est√£o', '```', '['))]
                        result = [topic for topic in result if topic and len(topic) > 1][:5]
                else:
                    # Fallback final
                    result = ["t√≥picos n√£o identificados"]
            
            return {
                "result": result,
                "prompt": prompt,
                "success": True
            }
        except Exception as e:
            self.logger.error(f"Erro ao extrair t√≥picos: {e}")
            return {
                "result": ["Erro ao extrair t√≥picos"],
                "prompt": prompt,
                "success": False,
                "error": str(e)
            }
    
    def _analyze_sentiment(self, conversation_text: str) -> Dict[str, Any]:
        """Analisar sentimento da conversa"""
        prompt = f"""
Analise o sentimento geral desta conversa do WhatsApp.

Conversa:
{conversation_text}

Instru√ß√µes:
- Analise o tom geral da conversa
- Identifique emo√ß√µes predominantes
- Responda em formato JSON com:
  - "overall_sentiment": "positivo", "negativo" ou "neutro"
  - "confidence": valor de 0 a 1
  - "emotions": lista de emo√ß√µes detectadas
  - "description": breve descri√ß√£o do sentimento

Resposta (formato JSON):
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            try:
                sentiment_data = json.loads(response.strip())
                return sentiment_data
            except json.JSONDecodeError:
                return {
                    "overall_sentiment": "neutro",
                    "confidence": 0.5,
                    "emotions": ["neutro"],
                    "description": response.strip()
                }
        except Exception as e:
            self.logger.error(f"Erro ao analisar sentimento: {e}")
            return {
                "overall_sentiment": "neutro",
                "confidence": 0.0,
                "emotions": ["erro"],
                "description": "Erro na an√°lise"
            }
    
    def _analyze_sentiment_with_prompt(self, conversation_text: str) -> Dict:
        """Analisar sentimento da conversa com prompt"""
        prompt = f"""
Analise o sentimento geral desta conversa do WhatsApp.

IMPORTANTE: A conversa pode incluir:
- Contexto hist√≥rico dos √∫ltimos 7 dias (marcado como HIST√ìRICO)
- Mensagens de √°udio transcritas (marcadas como [√ÅUDIO TRANSCRITO])
- An√°lises de imagens (marcadas como [IMAGEM ANALISADA])
- Mensagens de texto normais

Conversa:
{conversation_text}

Instru√ß√µes:
- Considere o contexto hist√≥rico para entender a evolu√ß√£o emocional
- Use as transcri√ß√µes de √°udio e an√°lises de imagem como conte√∫do real
- Analise o tom geral da conversa atual
- Identifique emo√ß√µes predominantes
- Responda em formato JSON com:
  - "overall_sentiment": "positivo", "negativo" ou "neutro"
  - "confidence": valor de 0 a 1
  - "emotions": lista de emo√ß√µes detectadas
  - "description": breve descri√ß√£o do sentimento

Resposta (formato JSON):
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            try:
                sentiment_data = json.loads(response.strip())
                result = sentiment_data
            except json.JSONDecodeError:
                result = {
                    "overall_sentiment": "neutro",
                    "confidence": 0.5,
                    "emotions": ["neutro"],
                    "description": response.strip()
                }
            
            return {
                "result": result,
                "prompt": prompt,
                "success": True
            }
        except Exception as e:
            self.logger.error(f"Erro ao analisar sentimento: {e}")
            return {
                "result": {
                    "overall_sentiment": "neutro",
                    "confidence": 0.0,
                    "emotions": ["erro"],
                    "description": "Erro na an√°lise"
                },
                "prompt": prompt,
                "success": False,
                "error": str(e)
            }
    
    def _generate_insights(self, conversation_text: str) -> List[str]:
        """Gerar insights sobre a conversa"""
        prompt = f"""
Analise esta conversa do WhatsApp e gere insights interessantes.

Conversa:
{conversation_text}

Instru√ß√µes:
- Identifique padr√µes comportamentais
- Destaque informa√ß√µes importantes
- Gere 2-3 insights relevantes
- Seja espec√≠fico e √∫til
- Responda em formato de lista

Insights:
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            insights = [line.strip() for line in response.strip().split('\n') if line.strip()]
            return insights[:3]
        except Exception as e:
            self.logger.error(f"Erro ao gerar insights: {e}")
            return ["Erro ao gerar insights"]
    
    def _generate_insights_with_prompt(self, conversation_text: str) -> Dict:
        """Gerar insights sobre a conversa com prompt"""
        prompt = f"""
Analise esta conversa do WhatsApp e gere insights interessantes.

IMPORTANTE: A conversa pode incluir:
- Contexto hist√≥rico dos √∫ltimos 7 dias (marcado como HIST√ìRICO)
- Mensagens de √°udio transcritas (marcadas como [√ÅUDIO TRANSCRITO])
- An√°lises de imagens (marcadas como [IMAGEM ANALISADA])
- Mensagens de texto normais

Conversa:
{conversation_text}

INSTRU√á√ïES CR√çTICAS:
- Identifique padr√µes comportamentais recorrentes
- Destaque informa√ß√µes importantes da conversa atual
- Compare com o hist√≥rico para identificar mudan√ßas
- Gere exatamente 3 insights relevantes e espec√≠ficos
- Cada insight deve ser uma frase clara e acion√°vel
- Responda APENAS com uma lista JSON v√°lida
- N√ÉO inclua texto explicativo, apenas o JSON
- N√ÉO use markdown, apenas JSON puro

FORMATO OBRIGAT√ìRIO:
["insight 1", "insight 2", "insight 3"]

EXEMPLOS V√ÅLIDOS:
["Cliente demonstra interesse recorrente em cursos de tecnologia", "Padr√£o de d√∫vidas sobre pre√ßos sugere sensibilidade financeira", "Comunica√ß√£o formal indica perfil corporativo"]

Responda APENAS com o JSON:
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            response_clean = response.strip()
            
            # Tentar parse JSON direto
            try:
                insights = json.loads(response_clean)
                if isinstance(insights, list):
                    result = insights
                else:
                    result = [str(insights)]
            except json.JSONDecodeError:
                # Tentar extrair JSON da resposta
                import re
                json_match = re.search(r'\[.*?\]', response_clean, re.DOTALL)
                if json_match:
                    try:
                        insights = json.loads(json_match.group())
                        result = insights if isinstance(insights, list) else [str(insights)]
                    except json.JSONDecodeError:
                        # Fallback: extrair insights das linhas
                        lines = [line.strip() for line in response_clean.split('\n') if line.strip()]
                        result = []
                        for line in lines:
                            line_clean = line.replace('"', '').replace(',', '').replace('**', '').replace('*', '').strip()
                            if line_clean and not line_clean.startswith(('Aqui est√£o', '```', '[', 'Insight')):
                                result.append(line_clean)
                        result = result[:3]
                else:
                    # Fallback final
                    result = ["insights n√£o identificados"]
            
            return {
                "result": result,
                "prompt": prompt,
                "success": True
            }
        except Exception as e:
            self.logger.error(f"Erro ao gerar insights: {e}")
            return {
                "result": ["Erro ao gerar insights"],
                "prompt": prompt,
                "success": False,
                "error": str(e)
            }
    
    def _calculate_stats(self, conversation_data: Dict) -> Dict[str, Any]:
        """Calcular estat√≠sticas da conversa"""
        total_messages = 0
        audio_messages = 0
        text_messages = 0
        total_contacts = len(conversation_data.get('contacts', []))
        
        for contact in conversation_data.get('contacts', []):
            messages = contact.get('messages', [])
            total_messages += len(messages)
            
            for message in messages:
                if message.get('message_type') == 'audio':
                    audio_messages += 1
                else:
                    text_messages += 1
        
        return {
            'total_contacts': total_contacts,
            'total_messages': total_messages,
            'audio_messages': audio_messages,
            'text_messages': text_messages,
            'audio_percentage': (audio_messages / total_messages * 100) if total_messages > 0 else 0
        }
    
    def _call_ollama(self, prompt: str, max_retries: int = 3, system_prompt: str = None) -> str:
        """Chamar API do Ollama com estat√≠sticas detalhadas"""
        start_time = time.time()
        
        # Calcular estat√≠sticas do prompt
        prompt_tokens = len(prompt.split())  # Aproxima√ß√£o simples
        system_tokens = len(system_prompt.split()) if system_prompt else 0
        total_input_tokens = prompt_tokens + system_tokens
        
        payload = {
            "model": self.model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.4,
                "top_p": 0.9,
                "repeat_penalty": 1.15,
                "num_predict": 1536
            }
        }
        
        # Adicionar system prompt se fornecido
        if system_prompt:
            payload["system"] = system_prompt
        
        for attempt in range(max_retries):
            try:
                self.logger.debug(f"üîÑ Chamada Ollama - Tentativa {attempt + 1}")
                self.logger.debug(f"üìä Input: {total_input_tokens} tokens (prompt: {prompt_tokens}, system: {system_tokens})")
                
                response = requests.post(
                    f"{self.base_url}/api/generate",
                    json=payload,
                    timeout=60
                )
                response.raise_for_status()
                
                result = response.json()
                response_text = result.get('response', '').strip()
                
                # Calcular estat√≠sticas da resposta
                end_time = time.time()
                duration = end_time - start_time
                output_tokens = len(response_text.split())  # Aproxima√ß√£o simples
                tokens_per_second = output_tokens / duration if duration > 0 else 0
                
                # Atualizar estat√≠sticas globais
                self.usage_stats["total_requests"] += 1
                self.usage_stats["total_input_tokens"] += total_input_tokens
                self.usage_stats["total_output_tokens"] += output_tokens
                self.usage_stats["total_time"] += duration
                
                # Log detalhado das estat√≠sticas
                self.logger.info(f"‚úÖ Ollama Response - {duration:.2f}s")
                self.logger.info(f"üìä Tokens: {total_input_tokens} ‚Üí {output_tokens} (total: {total_input_tokens + output_tokens})")
                self.logger.info(f"‚ö° Velocidade: {tokens_per_second:.2f} tokens/s")
                self.logger.info(f"üéØ Modelo: {self.model}")
                
                # Log de estat√≠sticas acumuladas
                total_tokens = self.usage_stats["total_input_tokens"] + self.usage_stats["total_output_tokens"]
                avg_speed = total_tokens / self.usage_stats["total_time"] if self.usage_stats["total_time"] > 0 else 0
                self.logger.info(f"üìà ACUMULADO: {self.usage_stats['total_requests']} requests, {total_tokens} tokens, {avg_speed:.2f} tokens/s m√©dio")
                
                # Log de performance
                if duration > 30:
                    self.logger.warning(f"‚ö†Ô∏è  Resposta lenta: {duration:.2f}s")
                elif duration < 5:
                    self.logger.info(f"üöÄ Resposta r√°pida: {duration:.2f}s")
                
                return response_text
                
            except Exception as e:
                if attempt == max_retries - 1:
                    self.logger.error(f"‚ùå Falha final ap√≥s {max_retries} tentativas: {e}")
                    raise e
                self.logger.warning(f"‚ö†Ô∏è  Tentativa {attempt + 1} falhou, tentando novamente: {e}")
                time.sleep(2 ** attempt)
        
        return ""
    
    def get_usage_stats(self) -> Dict:
        """Obter estat√≠sticas de uso do Ollama"""
        # Garantir que usage_stats existe
        if not hasattr(self, 'usage_stats'):
            self.usage_stats = {
                "total_requests": 0,
                "total_input_tokens": 0,
                "total_output_tokens": 0,
                "total_time": 0.0,
                "start_time": time.time()
            }
        
        uptime = time.time() - self.usage_stats["start_time"]
        total_tokens = self.usage_stats["total_input_tokens"] + self.usage_stats["total_output_tokens"]
        
        return {
            "model": self.model,
            "total_requests": self.usage_stats["total_requests"],
            "total_input_tokens": self.usage_stats["total_input_tokens"],
            "total_output_tokens": self.usage_stats["total_output_tokens"],
            "total_tokens": total_tokens,
            "total_time": self.usage_stats["total_time"],
            "uptime": uptime,
            "avg_tokens_per_second": total_tokens / self.usage_stats["total_time"] if self.usage_stats["total_time"] > 0 else 0,
            "requests_per_minute": self.usage_stats["total_requests"] / (uptime / 60) if uptime > 0 else 0,
            "avg_response_time": self.usage_stats["total_time"] / self.usage_stats["total_requests"] if self.usage_stats["total_requests"] > 0 else 0
        }
    
    def print_usage_stats(self):
        """Imprimir estat√≠sticas de uso"""
        stats = self.get_usage_stats()
        
        print("\n" + "=" * 60)
        print("üìä ESTAT√çSTICAS DE USO DO OLLAMA")
        print("=" * 60)
        print(f"ü§ñ Modelo: {stats['model']}")
        print(f"üìà Requests: {stats['total_requests']}")
        print(f"üì• Input Tokens: {stats['total_input_tokens']:,}")
        print(f"üì§ Output Tokens: {stats['total_output_tokens']:,}")
        print(f"üéØ Total Tokens: {stats['total_tokens']:,}")
        print(f"‚è±Ô∏è  Tempo Total: {stats['total_time']:.2f}s")
        print(f"üöÄ Velocidade M√©dia: {stats['avg_tokens_per_second']:.2f} tokens/s")
        print(f"üìä Requests/min: {stats['requests_per_minute']:.2f}")
        print(f"‚ö° Tempo M√©dio/Request: {stats['avg_response_time']:.2f}s")
        print(f"üïê Uptime: {stats['uptime']:.2f}s")
        print("=" * 60)
    
    def _analyze_contact(self, contact: Dict, diary_data: Dict, contact_idx: int) -> Optional[Dict]:
        """Analisar conversa individual de um contato"""
        try:
            contact_name = contact.get('contact_name', 'Desconhecido')
            messages = contact.get('messages', [])
            
            if not messages:
                return None
            
            # Preparar texto da conversa do contato
            conversation_text = self._prepare_contact_conversation_text(contact, diary_data)
            
            if not conversation_text.strip():
                return None
            
            # An√°lise completa do contato
            analysis = {
                'contact_name': contact_name,
                'contact_phone': contact.get('contact_phone', ''),
                'contact_key': contact.get('contact_key', ''),
                'contact_idx': contact_idx,
                'summary': self._generate_contact_summary(conversation_text, contact_name, diary_data),
                'topics': self._extract_contact_topics(conversation_text, contact_name, diary_data),
                'sentiment': self._analyze_contact_sentiment(conversation_text, contact_name, diary_data),
                'insights': self._generate_contact_insights(conversation_text, contact_name, diary_data),
                'conversation_stats': self._calculate_contact_stats(contact),
                'success': True,
                'analyzed_at': datetime.now().isoformat()
            }
            
            return analysis
            
        except Exception as e:
            self.logger.error(f"Erro ao analisar contato {contact.get('contact_name', 'Desconhecido')}: {e}")
            return {
                'contact_name': contact.get('contact_name', 'Desconhecido'),
                'contact_idx': contact_idx,
                'error': str(e),
                'success': False,
                'analyzed_at': datetime.now().isoformat()
            }
    
    def _prepare_contact_conversation_text(self, contact: Dict, diary_data: Dict) -> str:
        """Preparar texto da conversa de um contato espec√≠fico"""
        text_parts = []
        contact_name = contact.get('contact_name', 'Desconhecido')
        
        # Adicionar contexto hist√≥rico se dispon√≠vel
        historical_context = diary_data.get('historical_context', [])
        if historical_context:
            # Filtrar apenas mensagens deste contato
            contact_historical = [
                msg for msg in historical_context 
                if msg.get('contact_name') == contact_name or msg.get('contact_key') == contact.get('contact_key')
            ]
            
            if contact_historical:
                text_parts.append("=== CONTEXTO HIST√ìRICO (√öltimos 7 dias) ===")
                text_parts.append(f"Mensagens recentes com {contact_name}:")
                
                for msg in contact_historical[:5]:  # Limitar a 5 mensagens hist√≥ricas
                    timestamp = msg.get('timestamp', '')
                    message_type = msg.get('message_type', 'text')
                    text = msg.get('text', '')
                    
                    if text:
                        prefix = f"[{timestamp}] " if timestamp else ""
                        
                        # Adicionar prefixo baseado no tipo
                        if message_type == 'audio_transcribed':
                            prefix += "[√ÅUDIO HIST√ìRICO] "
                        elif message_type == 'image_analyzed':
                            prefix += "[IMAGEM HIST√ìRICA] "
                        elif message_type in ['audio', 'image']:
                            prefix += f"[{message_type.upper()} HIST√ìRICO] "
                        
                        text_parts.append(f"{prefix}{text}")
                
                text_parts.append("\n=== CONVERSA ATUAL ===")
        
        # Adicionar conversa atual do contato
        text_parts.append(f"\n=== Conversa com {contact_name} ===")
        
        for message in contact.get('messages', []):
            message_text = message.get('text', '')
            message_type = message.get('message_type', 'text')
            
            if message_text:
                timestamp = message.get('timestamp', '')
                from_me = message.get('from_me', False)
                sender = "Voc√™" if from_me else contact_name
                prefix = f"[{timestamp}] {sender}: " if timestamp else f"{sender}: "
                
                # Adicionar prefixo baseado no tipo
                if message_type == 'audio_transcribed':
                    prefix += "[√ÅUDIO TRANSCRITO] "
                elif message_type == 'image_analyzed':
                    prefix += "[IMAGEM ANALISADA] "
                elif message_type in ['audio', 'image']:
                    prefix += f"[{message_type.upper()}] "
                
                text_parts.append(f"{prefix}{message_text}")
        
        return "\n".join(text_parts)
    
    def _generate_contact_summary(self, conversation_text: str, contact_name: str, diary_data: Dict) -> Dict:
        """Gerar resumo da conversa com um contato espec√≠fico"""
        user_name = diary_data.get('user_name', 'Usu√°rio')
        company_name = diary_data.get('company_name', 'Empresa')
        date_formatted = diary_data.get('date_formatted', 'Data')
        
        prompt = f"""
CONTEXTO DA AN√ÅLISE:
Voc√™ est√° analisando uma conversa do WhatsApp Business de um dia de trabalho espec√≠fico.

DADOS DO USU√ÅRIO:
- Nome: {user_name}
- Empresa: {company_name}
- Data: {date_formatted}
- Papel: Funcion√°rio/Atendente da empresa

DADOS DO CONTATO:
- Nome: {contact_name}
- Papel: Cliente/Lead/Prospect da empresa
- Relacionamento: Conversa comercial/profissional

PROP√ìSITO DA AN√ÅLISE:
Esta an√°lise faz parte de um sistema de intelig√™ncia empresarial que:
1. Avalia a qualidade do atendimento ao cliente
2. Identifica oportunidades de melhoria no relacionamento
3. Extrai insights sobre necessidades dos clientes
4. Monitora padr√µes de comunica√ß√£o e vendas
5. Gera feedback para treinamento e desenvolvimento

CONVERSA A SER ANALISADA:
{conversation_text}

INSTRU√á√ïES ESPEC√çFICAS:
- Analise a conversa do ponto de vista de atendimento ao cliente
- Identifique o n√≠vel de satisfa√ß√£o do cliente {contact_name}
- Avalie a efetividade da comunica√ß√£o de {user_name}
- Destaque oportunidades de venda ou upsell
- Identifique problemas ou obje√ß√µes do cliente
- Avalie se o atendimento foi resolutivo
- Considere o contexto hist√≥rico para entender a evolu√ß√£o do relacionamento
- Use transcri√ß√µes de √°udio e an√°lises de imagem como conte√∫do real
- Seja objetivo e focado em insights acion√°veis

Resumo da conversa com {contact_name}:
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            return {
                "result": response.strip(),
                "prompt": prompt,
                "success": True
            }
        except Exception as e:
            self.logger.error(f"Erro ao gerar resumo do contato: {e}")
            return {
                "result": f"Erro ao gerar resumo da conversa com {contact_name}",
                "prompt": prompt,
                "success": False,
                "error": str(e)
            }
    
    def _extract_contact_topics(self, conversation_text: str, contact_name: str, diary_data: Dict) -> Dict:
        """Extrair t√≥picos da conversa com um contato espec√≠fico"""
        user_name = diary_data.get('user_name', 'Usu√°rio')
        company_name = diary_data.get('company_name', 'Empresa')
        
        prompt = f"""
CONTEXTO:
Voc√™ est√° analisando uma conversa comercial do WhatsApp Business entre:
- {user_name} (funcion√°rio da {company_name})
- {contact_name} (cliente/lead)

PROP√ìSITO:
Identificar os principais t√≥picos de neg√≥cio discutidos para categoriza√ß√£o e an√°lise de vendas.

CONVERSA:
{conversation_text}

INSTRU√á√ïES:
- Identifique 3-5 t√≥picos principais relacionados a NEG√ìCIOS/VENDAS/ATENDIMENTO
- Foque em: produtos, servi√ßos, pre√ßos, d√∫vidas, obje√ß√µes, necessidades, problemas
- Use palavras-chave comerciais (m√°ximo 3 palavras por t√≥pico)
- Responda APENAS com JSON v√°lido
- N√ÉO inclua texto explicativo

EXEMPLOS DE T√ìPICOS COMERCIAIS:
["produto", "pre√ßo", "desconto"]
["d√∫vida", "especifica√ß√£o", "prazo"]
["obje√ß√£o", "concorr√™ncia", "custo"]
["necessidade", "solu√ß√£o", "benef√≠cio"]

Responda APENAS com o JSON:
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            response_clean = response.strip()
            
            # Tentar parse JSON direto
            try:
                topics = json.loads(response_clean)
                if isinstance(topics, list):
                    result = topics
                else:
                    result = [str(topics)]
            except json.JSONDecodeError:
                # Tentar extrair JSON da resposta
                import re
                json_match = re.search(r'\[.*?\]', response_clean, re.DOTALL)
                if json_match:
                    try:
                        topics = json.loads(json_match.group())
                        result = topics if isinstance(topics, list) else [str(topics)]
                    except json.JSONDecodeError:
                        # Fallback: extrair t√≥picos das linhas
                        lines = [line.strip() for line in response_clean.split('\n') if line.strip()]
                        result = [line.replace('"', '').replace(',', '').strip() for line in lines if line and not line.startswith(('Aqui est√£o', '```', '['))]
                        result = [topic for topic in result if topic and len(topic) > 1][:5]
                else:
                    # Fallback final
                    result = ["t√≥picos n√£o identificados"]
            
            return {
                "result": result,
                "prompt": prompt,
                "success": True
            }
        except Exception as e:
            self.logger.error(f"Erro ao extrair t√≥picos do contato: {e}")
            return {
                "result": ["Erro ao extrair t√≥picos"],
                "prompt": prompt,
                "success": False,
                "error": str(e)
            }
    
    def _analyze_contact_sentiment(self, conversation_text: str, contact_name: str, diary_data: Dict) -> Dict:
        """Analisar sentimento da conversa com um contato espec√≠fico"""
        user_name = diary_data.get('user_name', 'Usu√°rio')
        company_name = diary_data.get('company_name', 'Empresa')
        
        prompt = f"""
CONTEXTO COMERCIAL:
Voc√™ est√° analisando o sentimento de uma conversa de vendas/atendimento entre:
- {user_name} (funcion√°rio da {company_name})
- {contact_name} (cliente/lead)

PROP√ìSITO:
Avaliar a satisfa√ß√£o do cliente e a efetividade do atendimento para melhorar o relacionamento comercial.

CONVERSA:
{conversation_text}

INSTRU√á√ïES:
- Analise o sentimento do CLIENTE ({contact_name}) em rela√ß√£o ao atendimento
- Avalie a efetividade da comunica√ß√£o do FUNCION√ÅRIO ({user_name})
- Identifique sinais de satisfa√ß√£o, insatisfa√ß√£o, interesse ou desinteresse
- Considere o contexto hist√≥rico para entender a evolu√ß√£o do relacionamento
- Use transcri√ß√µes de √°udio e an√°lises de imagem como conte√∫do real
- Foque em aspectos comerciais: interesse em comprar, confian√ßa, obje√ß√µes

Responda em formato JSON:
{{
  "overall_sentiment": "positivo/negativo/neutro",
  "confidence": 0.0-1.0,
  "emotions": ["interesse", "satisfa√ß√£o", "d√∫vida", "frustra√ß√£o", etc],
  "description": "Breve an√°lise do sentimento comercial"
}}

Resposta (formato JSON):
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            try:
                sentiment_data = json.loads(response.strip())
                result = sentiment_data
            except json.JSONDecodeError:
                result = {
                    "overall_sentiment": "neutro",
                    "confidence": 0.5,
                    "emotions": ["neutro"],
                    "description": response.strip()
                }
            
            return {
                "result": result,
                "prompt": prompt,
                "success": True
            }
        except Exception as e:
            self.logger.error(f"Erro ao analisar sentimento do contato: {e}")
            return {
                "result": {
                    "overall_sentiment": "neutro",
                    "confidence": 0.0,
                    "emotions": ["erro"],
                    "description": "Erro na an√°lise"
                },
                "prompt": prompt,
                "success": False,
                "error": str(e)
            }
    
    def _generate_contact_insights(self, conversation_text: str, contact_name: str, diary_data: Dict) -> Dict:
        """Gerar insights sobre a conversa com um contato espec√≠fico"""
        user_name = diary_data.get('user_name', 'Usu√°rio')
        company_name = diary_data.get('company_name', 'Empresa')
        
        prompt = f"""
CONTEXTO COMERCIAL:
Voc√™ est√° analisando uma conversa de vendas/atendimento entre:
- {user_name} (funcion√°rio da {company_name})
- {contact_name} (cliente/lead)

PROP√ìSITO:
Gerar insights acion√°veis para melhorar vendas, atendimento e relacionamento com o cliente.

CONVERSA:
{conversation_text}

INSTRU√á√ïES:
- Gere 3 insights COMERCIAIS espec√≠ficos sobre {contact_name}
- Foque em: perfil do cliente, necessidades, obje√ß√µes, oportunidades de venda
- Identifique padr√µes de comportamento e prefer√™ncias
- Destaque sinais de interesse ou desinteresse
- Compare com hist√≥rico para identificar evolu√ß√£o
- Cada insight deve ser acion√°vel para vendas/atendimento
- Responda APENAS com JSON v√°lido

EXEMPLOS DE INSIGHTS COMERCIAIS:
["Cliente demonstra alto interesse em produtos premium", "Sensibilidade a pre√ßos sugere foco em solu√ß√µes econ√¥micas", "Comunica√ß√£o formal indica perfil B2B corporativo"]
["Lead apresenta obje√ß√µes sobre prazo de entrega", "Necessidade espec√≠fica de customiza√ß√£o identificada", "Sinal de interesse em proposta comercial"]

Responda APENAS com o JSON:
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            response_clean = response.strip()
            
            # Tentar parse JSON direto
            try:
                insights = json.loads(response_clean)
                if isinstance(insights, list):
                    result = insights
                else:
                    result = [str(insights)]
            except json.JSONDecodeError:
                # Tentar extrair JSON da resposta
                import re
                json_match = re.search(r'\[.*?\]', response_clean, re.DOTALL)
                if json_match:
                    try:
                        insights = json.loads(json_match.group())
                        result = insights if isinstance(insights, list) else [str(insights)]
                    except json.JSONDecodeError:
                        # Fallback: extrair insights das linhas
                        lines = [line.strip() for line in response_clean.split('\n') if line.strip()]
                        result = []
                        for line in lines:
                            line_clean = line.replace('"', '').replace(',', '').replace('**', '').replace('*', '').strip()
                            if line_clean and not line_clean.startswith(('Aqui est√£o', '```', '[', 'Insight')):
                                result.append(line_clean)
                        result = result[:3]
                else:
                    # Fallback final
                    result = ["insights n√£o identificados"]
            
            return {
                "result": result,
                "prompt": prompt,
                "success": True
            }
        except Exception as e:
            self.logger.error(f"Erro ao gerar insights do contato: {e}")
            return {
                "result": ["Erro ao gerar insights"],
                "prompt": prompt,
                "success": False,
                "error": str(e)
            }
    
    def _calculate_contact_stats(self, contact: Dict) -> Dict[str, Any]:
        """Calcular estat√≠sticas da conversa com um contato"""
        messages = contact.get('messages', [])
        total_messages = len(messages)
        audio_messages = 0
        text_messages = 0
        image_messages = 0
        sent_messages = 0
        received_messages = 0
        
        for message in messages:
            message_type = message.get('message_type', 'text')
            from_me = message.get('from_me', False)
            
            if from_me:
                sent_messages += 1
            else:
                received_messages += 1
            
            if message_type == 'audio':
                audio_messages += 1
            elif message_type == 'image':
                image_messages += 1
            else:
                text_messages += 1
        
        return {
            'total_messages': total_messages,
            'sent_messages': sent_messages,
            'received_messages': received_messages,
            'audio_messages': audio_messages,
            'text_messages': text_messages,
            'image_messages': image_messages,
            'audio_percentage': (audio_messages / total_messages * 100) if total_messages > 0 else 0,
            'text_percentage': (text_messages / total_messages * 100) if total_messages > 0 else 0,
            'image_percentage': (image_messages / total_messages * 100) if total_messages > 0 else 0
        }
    
    def _generate_diary_summary(self, contact_analyses: List[Dict], diary_data: Dict) -> Dict:
        """Gerar resumo global do di√°rio baseado nas an√°lises dos contatos"""
        # Preparar dados consolidados
        successful_analyses = [ca for ca in contact_analyses if ca.get('success', False)]
        
        if not successful_analyses:
            return {
                "result": "Nenhuma an√°lise de contato v√°lida dispon√≠vel",
                "success": False
            }
        
        # Consolidar informa√ß√µes
        all_topics = []
        all_sentiments = []
        all_insights = []
        contact_summaries = []
        
        for analysis in successful_analyses:
            contact_name = analysis.get('contact_name', 'Desconhecido')
            
            # T√≥picos
            topics = analysis.get('topics', {}).get('result', [])
            if isinstance(topics, list):
                # Garantir que cada item √© uma string, n√£o uma lista
                for topic in topics:
                    if isinstance(topic, str):
                        all_topics.append(topic)
                    elif isinstance(topic, list):
                        all_topics.extend([str(t) for t in topic if isinstance(t, str)])
            
            # Sentimentos
            sentiment = analysis.get('sentiment', {}).get('result', {})
            if isinstance(sentiment, dict):
                all_sentiments.append(sentiment)
            
            # Insights
            insights = analysis.get('insights', {}).get('result', [])
            if isinstance(insights, list):
                # Garantir que cada item √© uma string, n√£o uma lista
                for insight in insights:
                    if isinstance(insight, str):
                        all_insights.append(insight)
                    elif isinstance(insight, list):
                        all_insights.extend([str(i) for i in insight if isinstance(i, str)])
            
            # Resumos
            summary = analysis.get('summary', {}).get('result', '')
            if summary:
                contact_summaries.append(f"{contact_name}: {summary}")
        
        # Gerar prompt para resumo global
        consolidated_text = f"""
RESUMOS DAS CONVERSAS:
{chr(10).join(contact_summaries)}

T√ìPICOS IDENTIFICADOS: {', '.join(set(all_topics))}

SENTIMENTOS: {len(all_sentiments)} conversas analisadas

INSIGHTS: {chr(10).join(set(all_insights))}
"""
        
        prompt = f"""
CONTEXTO EMPRESARIAL:
Voc√™ est√° analisando o desempenho comercial de um dia de trabalho espec√≠fico.

DADOS DO FUNCION√ÅRIO:
- Nome: {diary_data.get('user_name', 'Desconhecido')}
- Empresa: {diary_data.get('company_name', 'Desconhecida')}
- Data: {diary_data.get('date_formatted', 'Data n√£o dispon√≠vel')}
- Total de clientes atendidos: {len(contact_analyses)}

PROP√ìSITO DA AN√ÅLISE:
Gerar um relat√≥rio executivo estruturado para:
1. Avaliar performance comercial do funcion√°rio
2. Identificar oportunidades de melhoria
3. Destacar pontos fortes e fracos
4. Fornecer feedback acion√°vel para desenvolvimento
5. Analisar padr√µes de vendas e atendimento

DADOS CONSOLIDADOS DO DIA:
{consolidated_text}

INSTRU√á√ïES ESPEC√çFICAS:
- Analise o desempenho COMERCIAL do funcion√°rio
- Avalie qualidade do atendimento aos clientes
- Identifique padr√µes de vendas e convers√£o
- Destaque oportunidades de upsell/cross-sell perdidas
- Avalie efetividade da comunica√ß√£o
- Identifique necessidades de treinamento
- Forne√ßa feedback construtivo e acion√°vel
- Foque em insights comerciais pr√°ticos

FORMATO DE RESPOSTA OBRIGAT√ìRIO (JSON):
{{
  "executive_summary": "Resumo executivo geral do desempenho do dia",
  "key_insights": [
    "Insight 1 sobre padr√µes comerciais identificados",
    "Insight 2 sobre comportamento do funcion√°rio",
    "Insight 3 sobre oportunidades de neg√≥cio"
  ],
  "improvements": [
    "Melhoria 1 espec√≠fica e acion√°vel",
    "Melhoria 2 com foco em vendas/atendimento",
    "Melhoria 3 para desenvolvimento profissional"
  ],
  "feedback": {{
    "strengths": ["Ponto forte 1", "Ponto forte 2"],
    "weaknesses": ["Ponto de melhoria 1", "Ponto de melhoria 2"],
    "recommendations": ["Recomenda√ß√£o 1", "Recomenda√ß√£o 2"]
  }},
  "commercial_metrics": {{
    "customer_satisfaction": "alta/m√©dia/baixa",
    "sales_effectiveness": "alta/m√©dia/baixa",
    "communication_quality": "alta/m√©dia/baixa"
  }},
  "next_actions": [
    "A√ß√£o imediata 1 para implementar",
    "A√ß√£o de m√©dio prazo 2",
    "A√ß√£o de longo prazo 3"
  ]
}}

Responda APENAS com o JSON v√°lido:
"""
        
        try:
            response = self._call_ollama(prompt, system_prompt=self.system_prompt)
            
            # Tentar extrair JSON estruturado
            try:
                structured_data = json.loads(response.strip())
                
                # Validar campos obrigat√≥rios
                required_fields = ['executive_summary', 'key_insights', 'improvements', 'feedback']
                if all(field in structured_data for field in required_fields):
                    return {
                        "result": structured_data.get('executive_summary', ''),
                        "key_insights": structured_data.get('key_insights', []),
                        "improvements": structured_data.get('improvements', []),
                        "feedback": structured_data.get('feedback', {}),
                        "commercial_metrics": structured_data.get('commercial_metrics', {}),
                        "next_actions": structured_data.get('next_actions', []),
                        "prompt": prompt,
                        "success": True,
                        "consolidated_data": {
                            "total_contacts": len(contact_analyses),
                            "successful_analyses": len(successful_analyses),
                            "unique_topics": list(set(all_topics)),
                            "sentiment_summary": self._calculate_sentiment_summary(all_sentiments),
                            "raw_insights": list(set(all_insights))[:5]
                        }
                    }
                else:
                    # Fallback se JSON estiver incompleto
                    return {
                        "result": response.strip(),
                        "key_insights": [],
                        "improvements": [],
                        "feedback": {},
                        "commercial_metrics": {},
                        "next_actions": [],
                        "prompt": prompt,
                        "success": True,
                        "consolidated_data": {
                            "total_contacts": len(contact_analyses),
                            "successful_analyses": len(successful_analyses),
                            "unique_topics": list(set(all_topics)),
                            "sentiment_summary": self._calculate_sentiment_summary(all_sentiments),
                            "raw_insights": list(set(all_insights))[:5]
                        }
                    }
            except json.JSONDecodeError:
                # Fallback se n√£o conseguir fazer parse do JSON
                return {
                    "result": response.strip(),
                    "key_insights": [],
                    "improvements": [],
                    "feedback": {},
                    "commercial_metrics": {},
                    "next_actions": [],
                    "prompt": prompt,
                    "success": True,
                    "consolidated_data": {
                        "total_contacts": len(contact_analyses),
                        "successful_analyses": len(successful_analyses),
                        "unique_topics": list(set(all_topics)),
                        "sentiment_summary": self._calculate_sentiment_summary(all_sentiments),
                        "raw_insights": list(set(all_insights))[:5]
                    }
                }
        except Exception as e:
            self.logger.error(f"Erro ao gerar resumo global: {e}")
            return {
                "result": "Erro ao gerar resumo global do di√°rio",
                "key_insights": [],
                "improvements": [],
                "feedback": {},
                "commercial_metrics": {},
                "next_actions": [],
                "prompt": prompt,
                "success": False,
                "error": str(e)
            }
    
    def _calculate_sentiment_summary(self, sentiments: List[Dict]) -> Dict:
        """Calcular resumo dos sentimentos"""
        if not sentiments:
            return {"overall": "neutro", "confidence": 0.0}
        
        positive_count = sum(1 for s in sentiments if s.get('overall_sentiment') == 'positivo')
        negative_count = sum(1 for s in sentiments if s.get('overall_sentiment') == 'negativo')
        neutral_count = sum(1 for s in sentiments if s.get('overall_sentiment') == 'neutro')
        
        total = len(sentiments)
        
        if positive_count > negative_count and positive_count > neutral_count:
            overall = "positivo"
        elif negative_count > positive_count and negative_count > neutral_count:
            overall = "negativo"
        else:
            overall = "neutro"
        
        avg_confidence = sum(s.get('confidence', 0) for s in sentiments) / total
        
        return {
            "overall": overall,
            "confidence": avg_confidence,
            "positive_count": positive_count,
            "negative_count": negative_count,
            "neutral_count": neutral_count,
            "total_conversations": total
        }
    
    def _calculate_analysis_stats(self, contact_analyses: List[Dict], diary_data: Dict) -> Dict[str, Any]:
        """Calcular estat√≠sticas gerais da an√°lise"""
        successful_analyses = [ca for ca in contact_analyses if ca.get('success', False)]
        
        total_messages = sum(ca.get('conversation_stats', {}).get('total_messages', 0) for ca in successful_analyses)
        total_audio = sum(ca.get('conversation_stats', {}).get('audio_messages', 0) for ca in successful_analyses)
        total_text = sum(ca.get('conversation_stats', {}).get('text_messages', 0) for ca in successful_analyses)
        total_images = sum(ca.get('conversation_stats', {}).get('image_messages', 0) for ca in successful_analyses)
        
        return {
            'total_contacts': len(contact_analyses),
            'successful_analyses': len(successful_analyses),
            'failed_analyses': len(contact_analyses) - len(successful_analyses),
            'success_rate': (len(successful_analyses) / len(contact_analyses) * 100) if contact_analyses else 0,
            'total_messages_analyzed': total_messages,
            'total_audio_messages': total_audio,
            'total_text_messages': total_text,
            'total_image_messages': total_images,
            'user_name': diary_data.get('user_name', 'Desconhecido'),
            'company_name': diary_data.get('company_name', 'Desconhecida'),
            'diary_date': diary_data.get('date_formatted', 'Data n√£o dispon√≠vel')
        }
    
    def test_connection(self) -> Dict[str, Any]:
        """Testar conex√£o com Ollama"""
        self._ensure_initialized()
        self.logger.info("Testando conexao com Ollama...")
        
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=10)
            response.raise_for_status()
            
            models = response.json().get('models', [])
            model_names = [model['name'] for model in models]
            
            model_available = self.model in model_names
            if not model_available and model_names:
                self.model = model_names[0]
                model_available = True
            
            self.logger.info(f"Ollama conectado - {len(models)} modelos disponiveis")
            
            return {
                'connected': True,
                'model_available': model_available,
                'models': model_names,
                'selected_model': self.model
            }
            
        except Exception as e:
            self.logger.error(f"Erro de conexao: {e}")
            return {
                'connected': False,
                'error': str(e)
            }
    
    def test_simple_prompt(self, text: str = "Diga 'Ola' em portugues") -> Dict[str, Any]:
        """Testar prompt simples"""
        self._ensure_initialized()
        self.logger.info(f"Testando prompt simples: {text}")
        
        try:
            start_time = time.time()
            
            payload = {
                "model": self.model,
                "prompt": text,
                "stream": False,
                "options": {
                    "temperature": 0.4,
                    "top_p": 0.9,
                    "repeat_penalty": 1.15,
                    "num_predict": 1536
                }
            }
            
            response = requests.post(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            
            result = response.json()
            response_text = result.get('response', '').strip()
            response_time = time.time() - start_time
            
            self.logger.info(f"Resposta recebida em {response_time:.2f}s")
            
            return {
                'success': True,
                'response': response_text,
                'response_time': response_time,
                'model': self.model
            }
            
        except Exception as e:
            self.logger.error(f"Erro no prompt: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def test_analysis(self, sample_text: str) -> bool:
        """Testar an√°lise com texto de exemplo"""
        self._ensure_initialized()
        self.logger.info("Testando analise de conversa")
        
        try:
            test_data = {
                'conversation_id': 'test',
                'contacts': [{
                    'contact_name': 'Teste',
                    'messages': [{
                        'text': sample_text,
                        'message_type': 'text',
                        'timestamp': '10:00'
                    }]
                }]
            }
            
            result = self.analyze_conversation(test_data)
            
            if 'error' not in result:
                self.logger.info("Teste de analise OK")
                return True
            else:
                self.logger.error(f"Erro no teste: {result['error']}")
                return False
                
        except Exception as e:
            self.logger.error(f"Erro no teste: {e}")
            return False
    
    def run_full_test(self) -> Dict[str, Any]:
        """Executar teste completo"""
        self._ensure_initialized()
        self.logger.info("Iniciando teste completo do LlamaService")
        
        results = {}
        
        # Teste 1: Conex√£o
        connection_result = self.test_connection()
        results['connection'] = connection_result
        
        if not connection_result['connected']:
            self.logger.error("Teste interrompido - Ollama nao esta rodando")
            return results
        
        # Teste 2: Prompt simples
        simple_result = self.test_simple_prompt()
        results['simple_prompt'] = simple_result
        
        if not simple_result['success']:
            self.logger.error("Teste interrompido - Erro no prompt simples")
            return results
        
        # Teste 3: An√°lise de conversa
        analysis_result = self.test_analysis("Ola, como voce esta?")
        results['analysis'] = analysis_result
        
        self.logger.info("Teste completo finalizado")
        return results
